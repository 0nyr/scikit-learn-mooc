{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f3d6df",
   "metadata": {},
   "source": [
    "Wrap-Up Script from Module 3: [Hyperparameter Tuning](https://inria.github.io/scikit-learn-mooc/tuning/parameter_tuning_wrap_up_quiz.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2acdc",
   "metadata": {},
   "source": [
    "# ðŸ Wrap-up quiz 3\n",
    "\n",
    "This quiz requires some programming to be answered.\n",
    "\n",
    "Load the dataset file named `penguins.csv` with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07d1aae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "penguins = pd.read_csv(\"../datasets/penguins.csv\")  # adjust path if needed\n",
    "\n",
    "columns = [\"Body Mass (g)\", \"Flipper Length (mm)\", \"Culmen Length (mm)\"]\n",
    "target_name = \"Species\"\n",
    "\n",
    "penguins_non_missing = penguins[columns + [target_name]].dropna()\n",
    "X = penguins_non_missing[columns]\n",
    "y = penguins_non_missing[target_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31cc095",
   "metadata": {},
   "source": [
    "`penguins` is a pandas dataframe. The column â€œSpeciesâ€ contains the target variable. We extract the numerical columns that quantify some attributes of such animals and our goal is to predict their species based on those attributes stored in the dataframe named `data`.\n",
    "\n",
    "Inspect the loaded data to select the correct assertions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db0a90",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Inspect the target variable and select the correct assertions from the following proposals.\n",
    "\n",
    "a) The problem to be solved is a regression problem\n",
    "b) The problem to be solved is a binary classification problem (exactly 2 possible classes)\n",
    "c) The problem to be solved is a multiclass classification problem (more than 2 possible classes)\n",
    "\n",
    "Select a single answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4e13e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 342\n",
      "Number of features: 3\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples: %d\" % X.shape[0])\n",
    "print(\"Number of features: %d\" % X.shape[1])\n",
    "print(\"Number of classes: %d\" % y.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2436f837",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Inspect the statistics of the target and individual features to select the correct statements.\n",
    "\n",
    "a) The proportions of the class counts are balanced: there are approximately the same number of rows for each class\n",
    "b) The proportions of the class counts are imbalanced: some classes have more than twice as many rows than others\n",
    "c) The input features have similar scales (ranges of values)\n",
    "\n",
    "Select all answers that apply\n",
    "\n",
    "Hint: `data.describe()`, and `target.value_counts()` are methods that are helpful to answer to this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31401d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_classes: 3\n",
      "\n",
      "class counts:\n",
      " Species\n",
      "Adelie Penguin (Pygoscelis adeliae)          151\n",
      "Gentoo penguin (Pygoscelis papua)            123\n",
      "Chinstrap penguin (Pygoscelis antarctica)     68\n",
      "Name: count, dtype: int64\n",
      "\n",
      "class proportions:\n",
      " Species\n",
      "Adelie Penguin (Pygoscelis adeliae)          0.442\n",
      "Gentoo penguin (Pygoscelis papua)            0.360\n",
      "Chinstrap penguin (Pygoscelis antarctica)    0.199\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "max/min ratio: 2.2205882352941178\n",
      "imbalanced (max > 2*min)? True\n",
      "\n",
      "X.describe():\n",
      "        Body Mass (g)  Flipper Length (mm)  Culmen Length (mm)\n",
      "count     342.000000           342.000000          342.000000\n",
      "mean     4201.754386           200.915205           43.921930\n",
      "std       801.954536            14.061714            5.459584\n",
      "min      2700.000000           172.000000           32.100000\n",
      "25%      3550.000000           190.000000           39.225000\n",
      "50%      4050.000000           197.000000           44.450000\n",
      "75%      4750.000000           213.000000           48.500000\n",
      "max      6300.000000           231.000000           59.600000\n",
      "\n",
      "feature ranges:\n",
      " Body Mass (g)          3600.0\n",
      "Flipper Length (mm)      59.0\n",
      "Culmen Length (mm)       27.5\n",
      "Name: range, dtype: float64\n",
      "\n",
      "range ratios (max_range / min_range): 130.9090909090909\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"n_classes:\", y.nunique())\n",
    "print(\"\\nclass counts:\\n\", y.value_counts())\n",
    "print(\"\\nclass proportions:\\n\", y.value_counts(normalize=True).round(3))\n",
    "\n",
    "counts = y.value_counts()\n",
    "ratio = counts.max() / counts.min()\n",
    "print(\"\\nmax/min ratio:\", float(ratio))\n",
    "print(\"imbalanced (max > 2*min)?\", bool(ratio > 2))\n",
    "\n",
    "desc = X.describe()\n",
    "print(\"\\nX.describe():\\n\", desc)\n",
    "\n",
    "ranges = (desc.loc[\"max\"] - desc.loc[\"min\"]).rename(\"range\")\n",
    "print(\"\\nfeature ranges:\\n\", ranges)\n",
    "print(\"\\nrange ratios (max_range / min_range):\", float(ranges.max() / ranges.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38884ad8",
   "metadata": {},
   "source": [
    "Letâ€™s now consider the following pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a0dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", StandardScaler()),\n",
    "    (\"classifier\", KNeighborsClassifier(n_neighbors=5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba76a01e",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Evaluate the pipeline using stratified 10-fold cross-validation with the `balanced-accuracy` scoring metric to choose the correct statement in the list below.\n",
    "\n",
    "You can use:\n",
    "* `sklearn.model_selection.cross_validate` to perform the cross-validation routine;\n",
    "* provide an integer `10` to the parameter `cv` of `cross_validate` to use the cross-validation with 10 folds;\n",
    "* provide the string `\"balanced_accuracy\"` to the parameter `scoring` of `cross_validate`.\n",
    "\n",
    "a) The average cross-validated test balanced accuracy of the above pipeline is between 0.9 and 1.0\n",
    "b) The average cross-validated test balanced accuracy of the above pipeline is between 0.8 and 0.9\n",
    "c) The average cross-validated test balanced accuracy of the above pipeline is between 0.5 and 0.8\n",
    "\n",
    "Select a single answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18e9beee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation balanced accuracy scores: [1.         1.         1.         0.91880342 0.88253968 0.95238095\n",
      " 0.97777778 0.93015873 0.90793651 0.95238095]\n",
      "Mean balanced accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_5 = cross_validate(model, X, y, cv=10, scoring=\"balanced_accuracy\", return_train_score=False)\n",
    "cv_5[\"test_score\"]\n",
    "\n",
    "print(\"Cross-validation balanced accuracy scores:\", cv_5[\"test_score\"])\n",
    "print(\"Mean balanced accuracy: %.3f\" % np.mean(cv_5[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be945852",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Repeat the evaluation by setting the parameters in order to select the correct statements in the list below. We recall that you can use `model.get_params()` to list the parameters of the pipeline and use `model.set_params(param_name=param_value)` to update them. Remember that one way to compare two models is comparing the cross-validation test scores of both models fold-to-fold, i.e. counting the number of folds where one model has a better test score than the other.\n",
    "\n",
    "a) Looking at the individual cross-validation scores, using a model with `n_neighbors=5` is substantially better (at least 7 of the cross-validations scores are strictly better) than a model with `n_neighbors=51`\n",
    "b) Looking at the individual cross-validation scores, using a model with `n_neighbors=5` is substantially better (at least 7 of the cross-validations scores are strictly better) than a model with `n_neighbors=101`\n",
    "c) Looking at the individual cross-validation scores, a 5 nearest neighbors using a `StandardScaler` is substantially better (at least 7 of the cross-validations scores are strictly better) than a 5 nearest neighbors using the raw features (without scaling).\n",
    "\n",
    "Select all answers that apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2db9aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wins(5 > 51), losses, ties: (4, 2, 4)\n",
      "wins(5 > 101), losses, ties: (10, 0, 0)\n",
      "wins(StdScaler+5NN > raw+5NN), losses, ties: (10, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def cv_scores(pipeline):\n",
    "    res = cross_validate(pipeline, X, y, cv=10, scoring=\"balanced_accuracy\", return_train_score=False)\n",
    "    return res[\"test_score\"]\n",
    "\n",
    "def fold_wins(scores_a, scores_b):\n",
    "    # count folds where A strictly better than B\n",
    "    return int(np.sum(scores_a > scores_b)), int(np.sum(scores_a < scores_b)), int(np.sum(scores_a == scores_b))\n",
    "\n",
    "# n_neighbors=5 vs 51 vs 101 (with StandardScaler)\n",
    "m5  = clone(model).set_params(classifier__n_neighbors=5)\n",
    "m51 = clone(model).set_params(classifier__n_neighbors=51)\n",
    "m101= clone(model).set_params(classifier__n_neighbors=101)\n",
    "\n",
    "s5   = cv_scores(m5)\n",
    "s51  = cv_scores(m51)\n",
    "s101 = cv_scores(m101)\n",
    "\n",
    "print(\"wins(5 > 51), losses, ties:\", fold_wins(s5, s51))\n",
    "print(\"wins(5 > 101), losses, ties:\", fold_wins(s5, s101))\n",
    "\n",
    "# StandardScaler vs raw features, both with n_neighbors=5\n",
    "m5_raw = Pipeline(steps=[\n",
    "    (\"preprocessor\", None),  # None means passthrough in Pipeline\n",
    "    (\"classifier\", KNeighborsClassifier(n_neighbors=5)),\n",
    "])\n",
    "s5_raw = cv_scores(m5_raw)\n",
    "print(\"wins(StdScaler+5NN > raw+5NN), losses, ties:\", fold_wins(s5, s5_raw))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1791b441",
   "metadata": {},
   "source": [
    "We will now study the impact of different preprocessors defined in the list below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d93af379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "all_preprocessors = [\n",
    "    None,\n",
    "    StandardScaler(),\n",
    "    MinMaxScaler(),\n",
    "    QuantileTransformer(n_quantiles=100),\n",
    "    PowerTransformer(method=\"box-cox\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda46db",
   "metadata": {},
   "source": [
    "The [Box-Cox method](https://en.wikipedia.org/wiki/Power_transform#Box%E2%80%93Cox_transformation) is common preprocessing strategy for positive values. The other preprocessors work both for any kind of numerical features. If you are curious to read the details about those method, please feel free to read them up in the [preprocessing chapter](https://scikit-learn.org/stable/modules/preprocessing.html) of the scikit-learn user guide but this is not required to answer the quiz questions.\n",
    "\n",
    "## Question 5\n",
    "\n",
    "Use `sklearn.model_selection.GridSearchCV` to study the impact of the choice of the preprocessor and the number of neighbors on the stratified 10-fold cross-validated `balanced_accuracy` metric. We want to study the `n_neighbors` in the range `[5, 51, 101]` and `preprocessor` in the range `all_preprocessors`. Although we wouldnâ€™t do this in a real setting (and prefer using nested cross validation), for this question, do the cross-validation on the entire dataset.\n",
    "\n",
    "Which of the following statements hold:\n",
    "\n",
    "a) Looking at the individual cross-validation scores, the best ranked model using a `StandardScaler` is substantially better (at least 7 of the cross-validations scores are strictly better) than using any other preprocessor\n",
    "b) Using any of the preprocessors has always a better ranking than using no preprocessor, irrespective of the value of `n_neighbors`\n",
    "c) Looking at the individual cross-validation scores, the model with `n_neighbors=5` and `StandardScaler` is substantially better (at least 7 of the cross-validations scores are strictly better) than the model with `n_neighbors=51` and `StandardScaler`\n",
    "d) Looking at the individual cross-validation scores, the model with `n_neighbors=51` and `StandardScaler` is substantially better (at least 7 of the cross-validations scores are strictly better) than the model with `n_neighbors=101` and `StandardScaler`\n",
    "\n",
    "Select all answers that apply\n",
    "\n",
    "Hint: pass `{\"preprocessor\": all_preprocessors, \"classifier__n_neighbors\": [5, 51, 101]}` for the `param_grid` argument to the `GridSearchCV` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85632148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.952198</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'preprocessor':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.947778</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'preprocessor':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.947094</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'preprocessor':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.946960</td>\n",
       "      <td>{'classifier__n_neighbors': 5, 'preprocessor':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>0.941880</td>\n",
       "      <td>{'classifier__n_neighbors': 51, 'preprocessor'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>0.927277</td>\n",
       "      <td>{'classifier__n_neighbors': 51, 'preprocessor'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>0.922833</td>\n",
       "      <td>{'classifier__n_neighbors': 51, 'preprocessor'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.920293</td>\n",
       "      <td>{'classifier__n_neighbors': 51, 'preprocessor'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>0.876642</td>\n",
       "      <td>{'classifier__n_neighbors': 101, 'preprocessor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>0.862357</td>\n",
       "      <td>{'classifier__n_neighbors': 101, 'preprocessor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  \\\n",
       "1                 1         0.952198   \n",
       "2                 2         0.947778   \n",
       "3                 3         0.947094   \n",
       "4                 4         0.946960   \n",
       "6                 5         0.941880   \n",
       "8                 6         0.927277   \n",
       "9                 7         0.922833   \n",
       "7                 8         0.920293   \n",
       "11                9         0.876642   \n",
       "12               10         0.862357   \n",
       "\n",
       "                                               params  \n",
       "1   {'classifier__n_neighbors': 5, 'preprocessor':...  \n",
       "2   {'classifier__n_neighbors': 5, 'preprocessor':...  \n",
       "3   {'classifier__n_neighbors': 5, 'preprocessor':...  \n",
       "4   {'classifier__n_neighbors': 5, 'preprocessor':...  \n",
       "6   {'classifier__n_neighbors': 51, 'preprocessor'...  \n",
       "8   {'classifier__n_neighbors': 51, 'preprocessor'...  \n",
       "9   {'classifier__n_neighbors': 51, 'preprocessor'...  \n",
       "7   {'classifier__n_neighbors': 51, 'preprocessor'...  \n",
       "11  {'classifier__n_neighbors': 101, 'preprocessor...  \n",
       "12  {'classifier__n_neighbors': 101, 'preprocessor...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"preprocessor\": all_preprocessors,\n",
    "    \"classifier__n_neighbors\": [5, 51, 101],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=model,          # pipeline defined earlier\n",
    "    param_grid=param_grid,\n",
    "    cv=10,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    "    refit=False,              # we only need CV results\n",
    ")\n",
    "\n",
    "grid.fit(X, y)\n",
    "cvres = pd.DataFrame(grid.cv_results_)\n",
    "cvres[[\"rank_test_score\", \"mean_test_score\", \"params\"]].sort_values(\"rank_test_score\").head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b36b9d",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Evaluate the generalization performance of the best models found in each fold using nested cross-validation. Set `return_estimator=True` and `cv=10` for the outer loop. The scoring metric must be the `balanced-accuracy`. The mean generalization performance is\n",
    "\n",
    "a) better than 0.97\n",
    "b) between 0.92 and 0.97\n",
    "c) below 0.92\n",
    "\n",
    "Select a single answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88321035",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m p.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m + (\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(p,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmethod\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m.rstrip(\u001b[33m\"\u001b[39m\u001b[33m()\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(p, \u001b[33m\"\u001b[39m\u001b[33mmethod\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Best model using StandardScaler\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m best_std = \u001b[43mbest_row_for\u001b[49m\u001b[43m(\u001b[49m\u001b[43mStandardScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m scores_best_std = split_scores(best_std)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest(StandardScaler) params:\u001b[39m\u001b[33m\"\u001b[39m, best_std[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mmean:\u001b[39m\u001b[33m\"\u001b[39m, best_std[\u001b[33m\"\u001b[39m\u001b[33mmean_test_score\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mbest_row_for\u001b[39m\u001b[34m(preprocessor_obj)\u001b[39m\n\u001b[32m      7\u001b[39m sub = cvres[mask].copy()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# best by mean_test_score (rank_test_score is equivalent for selecting best)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msub\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean_test_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/phd/scikit-learn-mooc/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1192\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1190\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1191\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/phd/scikit-learn-mooc/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1753\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index by location index with a non-integer key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1752\u001b[39m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1753\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1755\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._ixs(key, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/phd/scikit-learn-mooc/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1686\u001b[39m, in \u001b[36m_iLocIndexer._validate_integer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1684\u001b[39m len_axis = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.obj._get_axis(axis))\n\u001b[32m   1685\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key >= len_axis \u001b[38;5;129;01mor\u001b[39;00m key < -len_axis:\n\u001b[32m-> \u001b[39m\u001b[32m1686\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msingle positional indexer is out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# Utility to extract per-fold test scores for one row of cv_results_\n",
    "def split_scores(row, n_splits=10):\n",
    "    return np.array([row[f\"split{i}_test_score\"] for i in range(n_splits)])\n",
    "\n",
    "def best_row_for(preprocessor_obj):\n",
    "    mask = cvres[\"param_preprocessor\"].apply(lambda p: p == preprocessor_obj)\n",
    "    sub = cvres[mask].copy()\n",
    "    # best by mean_test_score (rank_test_score is equivalent for selecting best)\n",
    "    return sub.sort_values(\"mean_test_score\", ascending=False).iloc[0]\n",
    "\n",
    "def pretty_preproc(p):\n",
    "    if p is None:\n",
    "        return \"None\"\n",
    "    return p.__class__.__name__ + (f\"({getattr(p, 'method', '')})\".rstrip(\"()\") if hasattr(p, \"method\") else \"\")\n",
    "\n",
    "# Best model using StandardScaler\n",
    "best_std = best_row_for(StandardScaler())\n",
    "scores_best_std = split_scores(best_std)\n",
    "\n",
    "print(\"Best(StandardScaler) params:\", best_std[\"params\"], \"mean:\", best_std[\"mean_test_score\"])\n",
    "\n",
    "# (a) Best(StandardScaler) vs best of each other preprocessor\n",
    "for p in all_preprocessors:\n",
    "    if p is None or isinstance(p, StandardScaler):\n",
    "        continue\n",
    "    best_p = best_row_for(p)\n",
    "    wins, losses, ties = fold_wins(scores_best_std, split_scores(best_p))\n",
    "    print(f\"Std best vs best {pretty_preproc(p)}: wins={wins}, losses={losses}, ties={ties}\")\n",
    "\n",
    "# (b) For each n_neighbors, check if EVERY preprocessor (excluding None) ranks better than None\n",
    "for k in [5, 51, 101]:\n",
    "    sub = cvres[cvres[\"param_classifier__n_neighbors\"] == k]\n",
    "    row_none = sub[sub[\"param_preprocessor\"].isna()].iloc[0]  # None appears as NaN in this DataFrame\n",
    "    rank_none = int(row_none[\"rank_test_score\"])\n",
    "    better_all = True\n",
    "    for p in all_preprocessors:\n",
    "        if p is None:\n",
    "            continue\n",
    "        row_p = sub[sub[\"param_preprocessor\"].apply(lambda z: z == p)].iloc[0]\n",
    "        if int(row_p[\"rank_test_score\"]) >= rank_none:\n",
    "            better_all = False\n",
    "    print(f\"n_neighbors={k}: all preprocessors rank better than None? {better_all} (rank_none={rank_none})\")\n",
    "\n",
    "# (c) & (d) StandardScaler with k=5 vs 51, and 51 vs 101 (fold-to-fold, â‰¥7 wins)\n",
    "def row_for(preproc_obj, k):\n",
    "    sub = cvres[\n",
    "        cvres[\"param_classifier__n_neighbors\"].eq(k)\n",
    "        & cvres[\"param_preprocessor\"].apply(lambda p: p == preproc_obj)\n",
    "    ]\n",
    "    return sub.iloc[0]\n",
    "\n",
    "r_std_5 = row_for(StandardScaler(), 5)\n",
    "r_std_51 = row_for(StandardScaler(), 51)\n",
    "r_std_101 = row_for(StandardScaler(), 101)\n",
    "\n",
    "print(\"StdScaler: wins(5 > 51), losses, ties:\", fold_wins(split_scores(r_std_5), split_scores(r_std_51)))\n",
    "print(\"StdScaler: wins(51 > 101), losses, ties:\", fold_wins(split_scores(r_std_51), split_scores(r_std_101)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56dbbcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.95238095, 0.92673993, 1.        , 0.91880342, 0.88253968,\n",
       "        1.        , 0.95555556, 0.93015873, 0.90793651, 0.95238095]),\n",
       " np.float64(0.9426495726495727))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "inner_grid = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=10,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "outer = cross_validate(\n",
    "    inner_grid,\n",
    "    X, y,\n",
    "    cv=10,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    return_estimator=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "outer[\"test_score\"], outer[\"test_score\"].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f695aa86",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "\n",
    "Explore the set of best parameters that the different grid search models found in each fold of the outer cross-validation. Remember that you can access them with the `best_params_` attribute of the estimator. Select all the statements that are true.\n",
    "\n",
    "a) The tuned number of nearest neighbors is stable across folds\n",
    "b) The tuned number of nearest neighbors changes often across folds\n",
    "c) The optimal scaler is stable across folds\n",
    "d) The optimal scaler changes often across folds\n",
    "\n",
    "Select all answers that apply\n",
    "\n",
    "Hint: it is important to pass `return_estimator=True` to the `cross_validate` function to be able to introspect trained model saved in the `\"estimator\"` field of the CV results. If you forgot to do for the previous question, please re-run the cross-validation with that option enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4abded2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'classifier__n_neighbors': 5,\n",
       "  'preprocessor': QuantileTransformer(n_quantiles=100)},\n",
       " {'classifier__n_neighbors': 5,\n",
       "  'preprocessor': QuantileTransformer(n_quantiles=100)},\n",
       " {'classifier__n_neighbors': 5, 'preprocessor': StandardScaler()},\n",
       " {'classifier__n_neighbors': 5, 'preprocessor': StandardScaler()},\n",
       " {'classifier__n_neighbors': 5, 'preprocessor': MinMaxScaler()},\n",
       " {'classifier__n_neighbors': 5,\n",
       "  'preprocessor': QuantileTransformer(n_quantiles=100)},\n",
       " {'classifier__n_neighbors': 5, 'preprocessor': MinMaxScaler()},\n",
       " {'classifier__n_neighbors': 5, 'preprocessor': StandardScaler()},\n",
       " {'classifier__n_neighbors': 5, 'preprocessor': StandardScaler()},\n",
       " {'classifier__n_neighbors': 5,\n",
       "  'preprocessor': QuantileTransformer(n_quantiles=100)}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = [est.best_params_ for est in outer[\"estimator\"]]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6b3b5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors counts: Counter({5: 10})\n",
      "preprocessor counts: Counter({'QuantileTransformer': 4, 'StandardScaler': 4, 'MinMaxScaler': 2})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "knn_values = [bp[\"classifier__n_neighbors\"] for bp in best_params]\n",
    "preprocs = [bp[\"preprocessor\"] for bp in best_params]\n",
    "\n",
    "print(\"n_neighbors counts:\", Counter(knn_values))\n",
    "print(\"preprocessor counts:\", Counter(type(p).__name__ if p is not None else \"None\" for p in preprocs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit-learn-mooc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
